{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
    "from data import ModelNet40\n",
    "from model import PointNet, DGCNN_cls\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from util import cal_loss, IOStream\n",
    "import sklearn.metrics as metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class args:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 32\n",
    "        self.num_points = 1024\n",
    "        self.no_cuda = True\n",
    "        self.seed = 1\n",
    "        self.exp_name = \"cls_1024_eval\"\n",
    "        self.model = \"dgcnn\"\n",
    "        self.dataset = \"modelnet40\"\n",
    "        self.test_batch_size = 16\n",
    "        self.epochs = 250\n",
    "        self.lr = 0.001\n",
    "        self.momentum = 0.9\n",
    "        self.scheduler = \"cos\"\n",
    "        self.dropout = 0.5\n",
    "        self.k = 20\n",
    "        self.model_path = \"pretrained/model.cls.1024.t7\"\n",
    "        self.emb_dims = 1024\n",
    "args = args()\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if not os.path.exists(\"outputs\"):\n",
    "    os.makedirs(\"outputs\")\n",
    "if not os.path.exists(\"outputs/\" + args.exp_name):\n",
    "    os.makedirs(\"outputs/\" + args.exp_name)\n",
    "if not os.path.exists(\"outputs/\" + args.exp_name + \"/\" + \"models\"):\n",
    "    os.makedirs(\"outputs/\" + args.exp_name + \"/\" + \"models\")\n",
    "os.system(\n",
    "    \"cp main_cls.py outputs\" + \"/\" + args.exp_name + \"/\" + \"main_cls.py.backup\"\n",
    ")\n",
    "os.system(\"cp model.py outputs\" + \"/\" + args.exp_name + \"/\" + \"model.py.backup\")\n",
    "os.system(\"cp util.py outputs\" + \"/\" + args.exp_name + \"/\" + \"util.py.backup\")\n",
    "os.system(\"cp data.py outputs\" + \"/\" + args.exp_name + \"/\" + \"data.py.backup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0064516129032258064\n",
      "0.012903225806451613\n",
      "0.01935483870967742\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/isabellaqian/code projects/cval/dgcnn.pytorch/main.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/isabellaqian/code%20projects/cval/dgcnn.pytorch/main.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/isabellaqian/code%20projects/cval/dgcnn.pytorch/main.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m batch_size \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/isabellaqian/code%20projects/cval/dgcnn.pytorch/main.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m logits \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/isabellaqian/code%20projects/cval/dgcnn.pytorch/main.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m preds \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39mmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/isabellaqian/code%20projects/cval/dgcnn.pytorch/main.ipynb#W1sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m test_true\u001b[39m.\u001b[39mappend(label\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cval/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cval/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:153\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(\u001b[39m\"\u001b[39m\u001b[39mDataParallel.forward\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    152\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids:\n\u001b[0;32m--> 153\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    155\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m chain(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39mparameters(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39mbuffers()):\n\u001b[1;32m    156\u001b[0m         \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mdevice \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_device_obj:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cval/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code projects/cval/dgcnn.pytorch/model.py:190\u001b[0m, in \u001b[0;36mDGCNN_cls.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    182\u001b[0m x4 \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\n\u001b[1;32m    183\u001b[0m     \u001b[39m0\u001b[39m\n\u001b[1;32m    184\u001b[0m ]  \u001b[39m# (batch_size, 256, num_points, k) -> (batch_size, 256, num_points)\u001b[39;00m\n\u001b[1;32m    186\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m    187\u001b[0m     (x1, x2, x3, x4), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    188\u001b[0m )  \u001b[39m# (batch_size, 64+64+128+256, num_points)\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv5(\n\u001b[1;32m    191\u001b[0m     x\n\u001b[1;32m    192\u001b[0m )  \u001b[39m# (batch_size, 64+64+128+256, num_points) -> (batch_size, emb_dims, num_points)\u001b[39;00m\n\u001b[1;32m    193\u001b[0m x1 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39madaptive_max_pool1d(x, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mview(\n\u001b[1;32m    194\u001b[0m     batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    195\u001b[0m )  \u001b[39m# (batch_size, emb_dims, num_points) -> (batch_size, emb_dims)\u001b[39;00m\n\u001b[1;32m    196\u001b[0m x2 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39madaptive_avg_pool1d(x, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mview(\n\u001b[1;32m    197\u001b[0m     batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    198\u001b[0m )  \u001b[39m# (batch_size, emb_dims, num_points) -> (batch_size, emb_dims)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cval/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cval/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cval/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cval/lib/python3.9/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cval/lib/python3.9/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#sample test\n",
    "test_loader = DataLoader(\n",
    "        ModelNet40(partition=\"test\", num_points=args.num_points),\n",
    "        batch_size=args.test_batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "\n",
    "# Try to load models\n",
    "if args.model == \"pointnet\":\n",
    "    model = PointNet(args).to(device)\n",
    "elif args.model == \"dgcnn\":\n",
    "    model = DGCNN_cls(args).to(device)\n",
    "else:\n",
    "    raise Exception(\"Not implemented\")\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(args.model_path, map_location=torch.device(\"cpu\")))\n",
    "model = model.eval()\n",
    "test_acc = 0.0\n",
    "count = 0.0\n",
    "test_true = []\n",
    "test_pred = []\n",
    "for data, label in test_loader:\n",
    "    count += 1\n",
    "    print(count / len(test_loader))\n",
    "    data, label = data.to(device), label.to(device).squeeze()\n",
    "    data = data.permute(0, 2, 1)\n",
    "    batch_size = data.size()[0]\n",
    "    logits = model(data)\n",
    "    preds = logits.max(dim=1)[1]\n",
    "    test_true.append(label.cpu().numpy())\n",
    "    test_pred.append(preds.detach().cpu().numpy())\n",
    "test_true = np.concatenate(test_true)\n",
    "test_pred = np.concatenate(test_pred)\n",
    "test_acc = metrics.accuracy_score(test_true, test_pred)\n",
    "avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n",
    "outstr = \"Test :: test acc: %.6f, test avg acc: %.6f\" % (\n",
    "    test_acc,\n",
    "    avg_per_class_acc,\n",
    ")\n",
    "print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGCNN_cls(\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (linear1): Linear(in_features=2048, out_features=512, bias=False)\n",
      "  (bn6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dp1): Dropout(p=0.5, inplace=False)\n",
      "  (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (bn7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dp2): Dropout(p=0.5, inplace=False)\n",
      "  (linear3): Linear(in_features=256, out_features=40, bias=True)\n",
      ")\n",
      "Let's use 0 GPUs!\n",
      "Use Adam\n",
      "tensor([34, 34, 30,  6, 28,  7, 26, 11,  4, 37, 28, 13, 34,  9, 26, 26, 32, 28,\n",
      "        25, 28, 17, 14,  9, 27,  7,  8, 10,  7, 29, 34,  8,  2])\n",
      "tensor([ 6,  2, 13,  3, 29,  7, 28, 38, 33, 26, 26, 35, 38, 34, 28, 26, 16, 38,\n",
      "         8,  6, 26, 29, 25, 28,  8,  9, 30, 16, 27, 25, 28, 38])\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "train_loader = DataLoader(\n",
    "        ModelNet40(partition=\"train\", num_points=args.num_points),\n",
    "        num_workers=8,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "test_loader = DataLoader(\n",
    "    ModelNet40(partition=\"test\", num_points=args.num_points),\n",
    "    num_workers=8,\n",
    "    batch_size=args.test_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Try to load models\n",
    "if args.model == \"pointnet\":\n",
    "    model = PointNet(args).to(device)\n",
    "elif args.model == \"dgcnn\":\n",
    "    model = DGCNN_cls(args).to(device)\n",
    "else:\n",
    "    raise Exception(\"Not implemented\")\n",
    "\n",
    "print(str(model))\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "\n",
    "\n",
    "print(\"Use Adam\")\n",
    "opt = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
    "\n",
    "if args.scheduler == \"cos\":\n",
    "    scheduler = CosineAnnealingLR(opt, args.epochs, eta_min=1e-3)\n",
    "elif args.scheduler == \"step\":\n",
    "    scheduler = StepLR(opt, step_size=20, gamma=0.7)\n",
    "\n",
    "criterion = cal_loss\n",
    "best_test_acc = 0\n",
    "\n",
    "EPSILON = 0.5\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    ####################\n",
    "    # Train\n",
    "    ####################\n",
    "    train_loss = 0.0\n",
    "    count = 0.0\n",
    "    model.train()\n",
    "    train_pred = []\n",
    "    train_true = []\n",
    "    for data, label in train_loader:\n",
    "        data, label = data.to(device), label.to(device).squeeze()\n",
    "        data = data.permute(0, 2, 1)\n",
    "        # print(data.size())\n",
    "        data.requires_grad = True\n",
    "        batch_size = data.size()[0]\n",
    "        opt.zero_grad()\n",
    "        logits = model(data)\n",
    "        loss = criterion(logits, label)\n",
    "        loss.backward()\n",
    "\n",
    "        #perform fgsm\n",
    "        data_grad = data.grad.data\n",
    "        perturbed = data + EPSILON * data_grad.sign()\n",
    "        perturbed = torch.clamp(perturbed, 0, 1)\n",
    "        perturbed_logits = model(perturbed)\n",
    "\n",
    "        opt.step()\n",
    "        preds = logits.max(dim=1)[1]\n",
    "        preds_perturbed = perturbed_logits.max(dim=1)[1]\n",
    "        print(preds)\n",
    "        print(preds_perturbed)\n",
    "        count += batch_size\n",
    "        train_loss += loss.item() * batch_size\n",
    "        train_true.append(label.cpu().numpy())\n",
    "        train_pred.append(preds.detach().cpu().numpy())\n",
    "        break\n",
    "    break\n",
    "    if args.scheduler == \"cos\":\n",
    "        scheduler.step()\n",
    "    elif args.scheduler == \"step\":\n",
    "        if opt.param_groups[0][\"lr\"] > 1e-5:\n",
    "            scheduler.step()\n",
    "        if opt.param_groups[0][\"lr\"] < 1e-5:\n",
    "            for param_group in opt.param_groups:\n",
    "                param_group[\"lr\"] = 1e-5\n",
    "    train_true = np.concatenate(train_true)\n",
    "    train_pred = np.concatenate(train_pred)\n",
    "    outstr = \"Train %d, loss: %.6f, train acc: %.6f, train avg acc: %.6f\" % (\n",
    "        epoch,\n",
    "        train_loss * 1.0 / count,\n",
    "        metrics.accuracy_score(train_true, train_pred),\n",
    "        metrics.balanced_accuracy_score(train_true, train_pred),\n",
    "    )\n",
    "    print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting sample\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "mod = DGCNN_cls(args).to(device)\n",
    "mod = nn.DataParallel(mod)\n",
    "mod.load_state_dict(torch.load(args.model_path, map_location=torch.device(\"cpu\")))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        ModelNet40(partition=\"train\", num_points=args.num_points),\n",
    "        num_workers=8,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "print(\"getting sample\")\n",
    "sample = None\n",
    "label = None\n",
    "for data, l in train_loader:\n",
    "    print(0)\n",
    "    data, l = data.to(device), l.to(device).squeeze()\n",
    "    sample, label = data, l\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0239,  0.1703, -0.1886],\n",
       "        [ 0.2270,  0.1237, -0.2483],\n",
       "        [ 0.2595,  0.1237, -0.4658],\n",
       "        ...,\n",
       "        [ 0.0851,  0.1819, -0.3375],\n",
       "        [-0.4187,  0.1703, -0.5937],\n",
       "        [ 0.0424,  0.0821,  0.9305]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
